{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train network notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is coded to help train a U-net using atrous (dilated) convolutions.\n",
    "It can be used either in GUI mode with jupyter or in console mode (TO CHECK)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the modules.\n",
    "We also import a set of configuration functions that help us when manipulation config files, which are the backbone of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "from AxonDeepSeg.config_tools import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the name of the directory we are going to save our model to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_model_save='model_christian_0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define the configuration of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'balanced_weights': [1.1, 1, 1.3],\n",
       " 'batch_norm_activate': True,\n",
       " 'batch_norm_decay_decay_activate': True,\n",
       " 'batch_norm_decay_decay_period': 24000,\n",
       " 'batch_norm_decay_ending_decay': 0.9,\n",
       " 'batch_norm_decay_starting_decay': 0.7,\n",
       " 'batch_size': 8,\n",
       " 'convolution_per_layer': [3, 3, 3, 3],\n",
       " 'da-elastic-activate': True,\n",
       " 'da-elastic-alpha_max': 9,\n",
       " 'da-elastic-order': 3,\n",
       " 'da-flipping-activate': True,\n",
       " 'da-flipping-order': 4,\n",
       " 'da-gaussian_blur-activate': True,\n",
       " 'da-gaussian_blur-order': 6,\n",
       " 'da-gaussian_blur-sigma_max': 1.5,\n",
       " 'da-noise_addition-activate': False,\n",
       " 'da-noise_addition-order': 5,\n",
       " 'da-random_rotation-activate': False,\n",
       " 'da-random_rotation-high_bound': 89,\n",
       " 'da-random_rotation-low_bound': 5,\n",
       " 'da-random_rotation-order': 2,\n",
       " 'da-rescaling-activate': False,\n",
       " 'da-rescaling-factor_max': 1.2,\n",
       " 'da-rescaling-order': 1,\n",
       " 'da-shifting-activate': True,\n",
       " 'da-shifting-order': 0,\n",
       " 'da-shifting-percentage_max': 0.1,\n",
       " 'da-type': 'all',\n",
       " 'dataset_mean': 120.95,\n",
       " 'dataset_variance': 60.23,\n",
       " 'depth': 4,\n",
       " 'dilation_rate': [[1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1]],\n",
       " 'downsampling': 'convolution',\n",
       " 'dropout': 0.75,\n",
       " 'features_per_convolution': [[[1, 16], [16, 16], [16, 16]],\n",
       "  [[16, 32], [32, 32], [32, 32]],\n",
       "  [[32, 64], [64, 64], [64, 64]],\n",
       "  [[64, 128], [128, 128], [128, 128]]],\n",
       " 'learning_rate': 0.001,\n",
       " 'learning_rate_decay_activate': True,\n",
       " 'learning_rate_decay_period': 16000,\n",
       " 'learning_rate_decay_rate': 0.99,\n",
       " 'learning_rate_decay_type': 'polynomial',\n",
       " 'n_classes': 3,\n",
       " 'size_of_convolutions_per_layer': [[5, 5, 5],\n",
       "  [3, 3, 3],\n",
       "  [3, 3, 3],\n",
       "  [3, 3, 3]],\n",
       " 'thresholds': [0, 0.2, 0.8],\n",
       " 'trainingset': 'SEM_3c_512',\n",
       " 'trainingset_patchsize': 512,\n",
       " 'weighted_cost-balanced_activate': True,\n",
       " 'weighted_cost-balanced_weights': [1.1, 1, 1.3],\n",
       " 'weighted_cost-boundaries_activate': False,\n",
       " 'weighted_cost-boundaries_sigma': 2,\n",
       " 'weighted_cost_activate': True}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_configuration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionnary with the updates\n",
    "update_dict={\n",
    "    'dilation_rate': [[1, 1, 1], [1, 1, 1], [1,1,1,1,1,1]],\n",
    "    'convolution_per_layer': [3, 3, 6],\n",
    "    'features_per_convolution': [[[1, 16], [16, 16], [16, 16]],\n",
    "  [[16, 32], [32, 32], [32, 32]],\n",
    "  [[32, 64], [64, 64], [64, 64],[64, 128], [128, 128], [128, 128]]],\n",
    "    'size_of_convolutions_per_layer': [[5, 5, 5],\n",
    "  [3, 3, 3],\n",
    "  [3, 3, 3, 3, 3, 3]]\n",
    "}\n",
    "\n",
    "\n",
    "config=update_config(default_configuration(),update_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnary with the updates\n",
    "update_dict={'batch_size':2,\n",
    "             'learning_rate_decay_period': 48000,\n",
    "             'batch_norm_decay_decay_period': 72000\n",
    "}\n",
    "\n",
    "\n",
    "config=update_config(default_configuration(),update_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'balanced_weights': [1.1, 1, 1.3],\n",
       " 'batch_norm_activate': True,\n",
       " 'batch_norm_decay_decay_activate': True,\n",
       " 'batch_norm_decay_decay_period': 72000,\n",
       " 'batch_norm_decay_ending_decay': 0.9,\n",
       " 'batch_norm_decay_starting_decay': 0.7,\n",
       " 'batch_size': 2,\n",
       " 'convolution_per_layer': [3, 3, 3, 3],\n",
       " 'da-elastic-activate': True,\n",
       " 'da-elastic-alpha_max': 9,\n",
       " 'da-elastic-order': 3,\n",
       " 'da-flipping-activate': True,\n",
       " 'da-flipping-order': 4,\n",
       " 'da-gaussian_blur-activate': True,\n",
       " 'da-gaussian_blur-order': 6,\n",
       " 'da-gaussian_blur-sigma_max': 1.5,\n",
       " 'da-noise_addition-activate': False,\n",
       " 'da-noise_addition-order': 5,\n",
       " 'da-random_rotation-activate': False,\n",
       " 'da-random_rotation-high_bound': 89,\n",
       " 'da-random_rotation-low_bound': 5,\n",
       " 'da-random_rotation-order': 2,\n",
       " 'da-rescaling-activate': False,\n",
       " 'da-rescaling-factor_max': 1.2,\n",
       " 'da-rescaling-order': 1,\n",
       " 'da-shifting-activate': True,\n",
       " 'da-shifting-order': 0,\n",
       " 'da-shifting-percentage_max': 0.1,\n",
       " 'da-type': 'all',\n",
       " 'dataset_mean': 120.95,\n",
       " 'dataset_variance': 60.23,\n",
       " 'depth': 4,\n",
       " 'dilation_rate': [[1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1]],\n",
       " 'downsampling': 'convolution',\n",
       " 'dropout': 0.75,\n",
       " 'features_per_convolution': [[[1, 16], [16, 16], [16, 16]],\n",
       "  [[16, 32], [32, 32], [32, 32]],\n",
       "  [[32, 64], [64, 64], [64, 64]],\n",
       "  [[64, 128], [128, 128], [128, 128]]],\n",
       " 'learning_rate': 0.001,\n",
       " 'learning_rate_decay_activate': True,\n",
       " 'learning_rate_decay_period': 48000,\n",
       " 'learning_rate_decay_rate': 0.99,\n",
       " 'learning_rate_decay_type': 'polynomial',\n",
       " 'n_classes': 3,\n",
       " 'size_of_convolutions_per_layer': [[5, 5, 5],\n",
       "  [3, 3, 3],\n",
       "  [3, 3, 3],\n",
       "  [3, 3, 3]],\n",
       " 'thresholds': [0, 0.2, 0.8],\n",
       " 'trainingset': 'SEM_3c_512',\n",
       " 'trainingset_patchsize': 512,\n",
       " 'weighted_cost-balanced_activate': True,\n",
       " 'weighted_cost-balanced_weights': [1.1, 1, 1.3],\n",
       " 'weighted_cost-boundaries_activate': False,\n",
       " 'weighted_cost-boundaries_sigma': 2,\n",
       " 'weighted_cost_activate': True}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create variables to be used by the network when training as well as the directory to store the model. If the directory already exists we add a timestamp at the end of the directory name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model = os.path.join('../models/', dir_model_save)\n",
    "if os.path.exists(path_model): #If the path exists already we add a timestamp at the end of dir name.\n",
    "    dir_model_save += '_' + str(int(time.time()))[-4:]\n",
    "    path_model = os.path.join('../models/', dir_model_save)\n",
    "os.makedirs(path_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then make sure that the config file is valid by using a function we imported. __update_config__ updates the first config (default_configuration()) with the second (config_network) so that the parameters in config_network are at least the parameters needed by the network to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that the config file has all the necessary parameters\n",
    "\n",
    "config_network = update_config(default_configuration(), config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Management of the config file: if it already exists, we load it, else, we write it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen parameters :\n",
      "\n",
      "trainingset_patchsize  -  512\n",
      "thresholds  -  [0, 0.2, 0.8]\n",
      "learning_rate_decay_type  -  polynomial\n",
      "convolution_per_layer  -  [3, 3, 3, 3]\n",
      "da-gaussian_blur-sigma_max  -  1.5\n",
      "da-shifting-percentage_max  -  0.1\n",
      "da-shifting-activate  -  True\n",
      "batch_norm_decay_decay_activate  -  True\n",
      "da-flipping-activate  -  True\n",
      "batch_norm_decay_starting_decay  -  0.7\n",
      "n_classes  -  3\n",
      "learning_rate_decay_activate  -  True\n",
      "trainingset  -  SEM_3c_512\n",
      "da-random_rotation-activate  -  False\n",
      "da-rescaling-activate  -  False\n",
      "batch_norm_decay_decay_period  -  72000\n",
      "da-shifting-order  -  0\n",
      "features_per_convolution  -  [[[1, 16], [16, 16], [16, 16]], [[16, 32], [32, 32], [32, 32]], [[32, 64], [64, 64], [64, 64]], [[64, 128], [128, 128], [128, 128]]]\n",
      "batch_norm_decay_ending_decay  -  0.9\n",
      "da-gaussian_blur-order  -  6\n",
      "size_of_convolutions_per_layer  -  [[5, 5, 5], [3, 3, 3], [3, 3, 3], [3, 3, 3]]\n",
      "da-gaussian_blur-activate  -  True\n",
      "dataset_mean  -  120.95\n",
      "dilation_rate  -  [[1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1]]\n",
      "da-rescaling-factor_max  -  1.2\n",
      "dropout  -  0.75\n",
      "da-type  -  all\n",
      "weighted_cost_activate  -  True\n",
      "da-random_rotation-high_bound  -  89\n",
      "dataset_variance  -  60.23\n",
      "weighted_cost-balanced_weights  -  [1.1, 1, 1.3]\n",
      "da-rescaling-order  -  1\n",
      "da-elastic-alpha_max  -  9\n",
      "weighted_cost-boundaries_activate  -  False\n",
      "da-elastic-activate  -  True\n",
      "da-flipping-order  -  4\n",
      "da-random_rotation-low_bound  -  5\n",
      "weighted_cost-balanced_activate  -  True\n",
      "balanced_weights  -  [1.1, 1, 1.3]\n",
      "learning_rate_decay_period  -  48000\n",
      "downsampling  -  convolution\n",
      "learning_rate  -  0.001\n",
      "da-random_rotation-order  -  2\n",
      "batch_size  -  2\n",
      "da-elastic-order  -  3\n",
      "batch_norm_activate  -  True\n",
      "learning_rate_decay_rate  -  0.99\n",
      "da-noise_addition-activate  -  False\n",
      "weighted_cost-boundaries_sigma  -  2\n",
      "depth  -  4\n",
      "da-noise_addition-order  -  5\n"
     ]
    }
   ],
   "source": [
    "path_config_file=os.path.join(path_model,'config_network.json')\n",
    "if os.path.exists(path_config_file): # if there is already a configfile\n",
    "    with open(path_config_file, 'r') as fd:\n",
    "        config_network = json.loads(fd.read())\n",
    "else: # There is no config file for the moment\n",
    "    with open(path_config_file, 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "        config_network=config\n",
    "   \n",
    "print 'Chosen parameters :\\n'\n",
    "for param_name, param_value in config_network.iteritems():\n",
    "    print param_name, ' - ', param_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We indicate to the network where to find our trainingset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_trainingset = os.path.join('../data/', config_network[\"trainingset\"], 'training/')\n",
    "path_model_init=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last part, but not the least: actually training the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters to train: 125795\n",
      "training start\n",
      "Weighted cost selected\n",
      "2018-01-14 13:13:54.378468-epoch:1-loss:0.9378167637463273-acc:0.5910731307391462\n",
      "2018-01-14 13:14:39.783041-epoch:2-loss:0.8630186134371265-acc:0.6396939507846175\n",
      "2018-01-14 13:15:24.838102-epoch:3-loss:0.8262268777551323-acc:0.6717092559255403\n",
      "2018-01-14 13:16:10.481760-epoch:4-loss:0.8333541792014549-acc:0.6547117521022928\n",
      "2018-01-14 13:16:56.302552-epoch:5-loss:0.8040626994494734-acc:0.6702900570014427\n",
      "2018-01-14 13:17:41.816268-epoch:6-loss:0.8026461354617414-acc:0.6577420727959995\n",
      "2018-01-14 13:18:27.075830-epoch:7-loss:0.7985694881143242-acc:0.6617052801724138\n",
      "2018-01-14 13:19:12.697855-epoch:8-loss:0.7479385898031038-acc:0.6859945120482609\n",
      "2018-01-14 13:19:58.171088-epoch:9-loss:0.7305560358639422-acc:0.6966964458597118\n",
      "2018-01-14 13:20:43.659409-epoch:10-loss:0.6949410335770969-acc:0.7259770117957016\n",
      "Best accuracy model saved in file: ../models/model_christian_0/best_acc_model.ckpt\n",
      "Best loss model saved in file: ../models/model_christian_0/best_loss_model.ckpt\n",
      "2018-01-14 13:21:30.057044-epoch:11-loss:0.647966717851573-acc:0.7515461342088108\n",
      "2018-01-14 13:22:15.231949-epoch:12-loss:0.6489474424000444-acc:0.7384786955241499\n",
      "2018-01-14 13:23:00.597237-epoch:13-loss:0.643403123164999-acc:0.7500001356519501\n",
      "2018-01-14 13:23:46.078068-epoch:14-loss:0.6586891885461479-acc:0.7191738260203394\n",
      "2018-01-14 13:24:31.467713-epoch:15-loss:0.6183124945081514-acc:0.7577269940540708\n",
      "Best accuracy model saved in file: ../models/model_christian_0/best_acc_model.ckpt\n",
      "Best loss model saved in file: ../models/model_christian_0/best_loss_model.ckpt\n",
      "2018-01-14 13:25:17.844279-epoch:16-loss:0.5955114344070698-acc:0.7761686937562351\n",
      "2018-01-14 13:26:03.316735-epoch:17-loss:0.5869930489309904-acc:0.7686843872070312\n",
      "2018-01-14 13:26:49.142086-epoch:18-loss:0.567563899632158-acc:0.7819170458563443\n",
      "2018-01-14 13:27:34.703001-epoch:19-loss:0.568465491821026-acc:0.7852321493214575\n",
      "2018-01-14 13:28:20.369242-epoch:20-loss:0.5647908695812883-acc:0.7880543655362622\n",
      "Best accuracy model saved in file: ../models/model_christian_0/best_acc_model.ckpt\n",
      "Best loss model saved in file: ../models/model_christian_0/best_loss_model.ckpt\n",
      "2018-01-14 13:29:07.107619-epoch:21-loss:0.5400255754076201-acc:0.7973584162777869\n",
      "2018-01-14 13:29:52.918766-epoch:22-loss:0.5420361346211927-acc:0.7986542253658689\n",
      "2018-01-14 13:30:38.350728-epoch:23-loss:0.528216472987471-acc:0.8021138968138859\n",
      "2018-01-14 13:31:24.279165-epoch:24-loss:0.574389948927123-acc:0.7684061773892107\n",
      "2018-01-14 13:32:09.817220-epoch:25-loss:0.5289531082942568-acc:0.7999679302347118\n",
      "Best accuracy model saved in file: ../models/model_christian_0/best_acc_model.ckpt\n",
      "Best loss model saved in file: ../models/model_christian_0/best_loss_model.ckpt\n",
      "2018-01-14 13:32:55.962558-epoch:26-loss:0.5500890037109112-acc:0.7909870825964829\n",
      "2018-01-14 13:33:41.648324-epoch:27-loss:0.5264521015101465-acc:0.7966875577795094\n",
      "2018-01-14 13:34:27.488595-epoch:28-loss:0.5183170067852941-acc:0.8066736418625404\n",
      "2018-01-14 13:35:12.902699-epoch:29-loss:0.535886209586571-acc:0.798034273344895\n",
      "2018-01-14 13:35:58.561323-epoch:30-loss:0.5290258937868578-acc:0.7906638815485197\n",
      "Best accuracy model saved in file: ../models/model_christian_0/best_acc_model.ckpt\n",
      "Best loss model saved in file: ../models/model_christian_0/best_loss_model.ckpt\n",
      "2018-01-14 13:36:45.040347-epoch:31-loss:0.5234756716366472-acc:0.7948559728162041\n",
      "2018-01-14 13:37:30.616308-epoch:32-loss:0.5556506021269437-acc:0.7768830903645219\n",
      "2018-01-14 13:38:16.198563-epoch:33-loss:0.49458232522010803-acc:0.8122913775772884\n",
      "2018-01-14 13:39:00.782056-epoch:34-loss:0.498046875-acc:0.8132345244802277\n",
      "2018-01-14 13:39:46.411492-epoch:35-loss:0.49919471350209466-acc:0.8077034826936393\n",
      "Best accuracy model saved in file: ../models/model_christian_0/best_acc_model.ckpt\n",
      "Best loss model saved in file: ../models/model_christian_0/best_loss_model.ckpt\n",
      "2018-01-14 13:40:32.771442-epoch:36-loss:0.5324610348405509-acc:0.7936160667189236\n",
      "2018-01-14 13:41:18.323285-epoch:37-loss:0.4881178428386819-acc:0.8125731390098045\n",
      "2018-01-14 13:42:03.953167-epoch:38-loss:0.5062282743125126-acc:0.8025586337878786\n",
      "2018-01-14 13:42:49.738529-epoch:39-loss:0.5032726557090365-acc:0.798280915309643\n",
      "2018-01-14 13:43:35.411020-epoch:40-loss:0.5061092284219018-acc:0.8001543262909199\n",
      "Best accuracy model saved in file: ../models/model_christian_0/best_acc_model.ckpt\n",
      "Best loss model saved in file: ../models/model_christian_0/best_loss_model.ckpt\n",
      "2018-01-14 13:44:21.683448-epoch:41-loss:0.49874229266725734-acc:0.8041331891355843\n",
      "2018-01-14 13:45:07.345464-epoch:42-loss:0.47175058105896256-acc:0.8140273279157177\n",
      "2018-01-14 13:45:52.864265-epoch:43-loss:0.5109384018799354-acc:0.7962655712818277\n",
      "2018-01-14 13:46:38.440594-epoch:44-loss:0.4814572406226191-acc:0.8075444431140505\n",
      "2018-01-14 13:47:24.185981-epoch:45-loss:0.4969033033683382-acc:0.7988533829820568\n",
      "Best accuracy model saved in file: ../models/model_christian_0/best_acc_model.ckpt\n",
      "Best loss model saved in file: ../models/model_christian_0/best_loss_model.ckpt\n",
      "2018-01-14 13:48:10.446851-epoch:46-loss:0.4659520582906131-acc:0.8153160378850739\n",
      "2018-01-14 13:48:55.994848-epoch:47-loss:0.49806262604121504-acc:0.8078967127306708\n",
      "2018-01-14 13:49:41.555077-epoch:48-loss:0.46450175807393823-acc:0.8194173574447632\n",
      "2018-01-14 13:50:27.116988-epoch:49-loss:0.49483324124895295-acc:0.8069672379000434\n",
      "2018-01-14 13:51:12.513525-epoch:50-loss:0.5007936872284988-acc:0.7961182388766058\n",
      "Best accuracy model saved in file: ../models/model_christian_0/best_acc_model.ckpt\n",
      "Best loss model saved in file: ../models/model_christian_0/best_loss_model.ckpt\n",
      "Model saved in file: ../models/model_christian_0/model.ckpt\n",
      "2018-01-14 13:51:59.265223-epoch:51-loss:0.47149941222421055-acc:0.8112041888565853\n",
      "2018-01-14 13:52:44.689152-epoch:52-loss:0.47554482879309823-acc:0.8109123008004551\n",
      "2018-01-14 13:53:30.325502-epoch:53-loss:0.4720962479196746-acc:0.812462383303149\n",
      "2018-01-14 13:54:15.885975-epoch:54-loss:0.48187359345370323-acc:0.8068439857713107\n",
      "2018-01-14 13:55:01.623062-epoch:55-loss:0.4807875176955914-acc:0.8037884112062126\n",
      "Best accuracy model saved in file: ../models/model_christian_0/best_acc_model.ckpt\n",
      "Best loss model saved in file: ../models/model_christian_0/best_loss_model.ckpt\n",
      "2018-01-14 13:55:47.792867-epoch:56-loss:0.46207043836856715-acc:0.8121524679249731\n",
      "2018-01-14 13:56:33.347965-epoch:57-loss:0.480138151810087-acc:0.8044501974664886\n",
      "2018-01-14 13:57:19.063880-epoch:58-loss:0.4493319515524239-acc:0.8149666601213916\n",
      "2018-01-14 13:58:04.703266-epoch:59-loss:0.4544080115597824-acc:0.8221705185955969\n",
      "2018-01-14 13:58:50.342818-epoch:60-loss:0.4764418519776443-acc:0.8095710976370449\n",
      "Best accuracy model saved in file: ../models/model_christian_0/best_acc_model.ckpt\n",
      "Best loss model saved in file: ../models/model_christian_0/best_loss_model.ckpt\n",
      "2018-01-14 13:59:36.808787-epoch:61-loss:0.47404608335988274-acc:0.8058943933454054\n",
      "2018-01-14 14:00:22.426947-epoch:62-loss:0.46486629083238795-acc:0.8086680708260372\n",
      "2018-01-14 14:01:07.554883-epoch:63-loss:0.4649782581575985-acc:0.8090867667362607\n",
      "2018-01-14 14:01:53.247338-epoch:64-loss:0.4673902803453906-acc:0.8097489435097267\n",
      "2018-01-14 14:02:38.920561-epoch:65-loss:0.4666299634966357-acc:0.8132364996548356\n",
      "Best accuracy model saved in file: ../models/model_christian_0/best_acc_model.ckpt\n",
      "Best loss model saved in file: ../models/model_christian_0/best_loss_model.ckpt\n",
      "2018-01-14 14:03:24.762477-epoch:66-loss:0.47067846306439104-acc:0.8084757574673357\n",
      "2018-01-14 14:04:10.496469-epoch:67-loss:0.45796922979683713-acc:0.8133258120767002\n",
      "2018-01-14 14:04:56.121331-epoch:68-loss:0.4649725844120157-acc:0.8173179585358192\n",
      "2018-01-14 14:05:41.855638-epoch:69-loss:0.46219217263419055-acc:0.8158589026023602\n",
      "2018-01-14 14:06:27.893384-epoch:70-loss:0.4604338602773074-acc:0.8123679325498385\n",
      "Best accuracy model saved in file: ../models/model_christian_0/best_acc_model.ckpt\n",
      "Best loss model saved in file: ../models/model_christian_0/best_loss_model.ckpt\n",
      "2018-01-14 14:07:14.300377-epoch:71-loss:0.43175092442282315-acc:0.8259074749617742\n",
      "2018-01-14 14:08:00.068008-epoch:72-loss:0.4490737010692728-acc:0.8189509182140745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-14 14:08:45.515202-epoch:73-loss:0.45235559960891464-acc:0.8158041834831238\n",
      "2018-01-14 14:09:30.940395-epoch:74-loss:0.46899719793221045-acc:0.8071519218642136\n",
      "2018-01-14 14:10:16.521286-epoch:75-loss:0.471292527585194-acc:0.8094638914897523\n",
      "Best accuracy model saved in file: ../models/model_christian_0/best_acc_model.ckpt\n",
      "Best loss model saved in file: ../models/model_christian_0/best_loss_model.ckpt\n",
      "2018-01-14 14:11:02.983411-epoch:76-loss:0.46990442378767605-acc:0.8079438004000433\n",
      "2018-01-14 14:11:48.355394-epoch:77-loss:0.4494282438837248-acc:0.8192879228756345\n",
      "2018-01-14 14:12:33.968169-epoch:78-loss:0.4264036355347469-acc:0.8269132396270489\n",
      "2018-01-14 14:13:19.660060-epoch:79-loss:0.44589452805190255-acc:0.8130895700947991\n",
      "2018-01-14 14:14:05.263774-epoch:80-loss:0.4528781864149817-acc:0.8155044008945597\n",
      "Best accuracy model saved in file: ../models/model_christian_0/best_acc_model.ckpt\n",
      "Best loss model saved in file: ../models/model_christian_0/best_loss_model.ckpt\n",
      "2018-01-14 14:14:51.627513-epoch:81-loss:0.44699040569108106-acc:0.8182071796778975\n",
      "2018-01-14 14:15:37.093965-epoch:82-loss:0.45092072260790855-acc:0.8132675413427682\n",
      "2018-01-14 14:16:22.383186-epoch:83-loss:0.4453011617578309-acc:0.8199893030627021\n",
      "2018-01-14 14:17:08.197750-epoch:84-loss:0.4581891997107144-acc:0.8100575434750525\n",
      "2018-01-14 14:17:54.231881-epoch:85-loss:0.43255582451820374-acc:0.8217528729603207\n",
      "Best accuracy model saved in file: ../models/model_christian_0/best_acc_model.ckpt\n",
      "Best loss model saved in file: ../models/model_christian_0/best_loss_model.ckpt\n",
      "2018-01-14 14:18:41.292011-epoch:86-loss:0.4384448518013132-acc:0.8197894918507543\n",
      "2018-01-14 14:19:26.715959-epoch:87-loss:0.4699987481380331-acc:0.7994551781950325\n",
      "2018-01-14 14:20:12.407534-epoch:88-loss:0.4569962086348698-acc:0.80885328301068\n",
      "2018-01-14 14:20:57.791938-epoch:89-loss:0.4673929204200876-acc:0.804262886787283\n",
      "2018-01-14 14:21:43.579579-epoch:90-loss:0.43508490920066833-acc:0.819773704841219\n",
      "2018-01-14 14:22:29.028481-epoch:91-loss:0.43924769656411533-acc:0.816166980513211\n",
      "2018-01-14 14:23:14.617165-epoch:92-loss:0.4616686290708082-acc:0.8074273775363792\n",
      "2018-01-14 14:24:00.330259-epoch:93-loss:0.45012275103865-acc:0.8130653664983553\n",
      "2018-01-14 14:24:45.818397-epoch:94-loss:0.44492510063894863-acc:0.8174825249047115\n",
      "2018-01-14 14:25:31.503012-epoch:95-loss:0.42044323682785034-acc:0.8259752228342254\n",
      "2018-01-14 14:26:17.236647-epoch:96-loss:0.4293274889732229-acc:0.8213579880780186\n",
      "2018-01-14 14:27:02.759173-epoch:97-loss:0.4278736864698345-acc:0.8224312334225096\n",
      "2018-01-14 14:27:48.224311-epoch:98-loss:0.44054798627721853-acc:0.8215528048318008\n",
      "2018-01-14 14:28:33.404564-epoch:99-loss:0.42365799176281893-acc:0.8259865374400698\n",
      "2018-01-14 14:29:19.016561-epoch:100-loss:0.4271593104148733-acc:0.8238254456684506\n",
      "Best accuracy model saved in file: ../models/model_christian_0/best_acc_model.ckpt\n",
      "Best loss model saved in file: ../models/model_christian_0/best_loss_model.ckpt\n",
      "Model saved in file: ../models/model_christian_0/model.ckpt\n",
      "2018-01-14 14:30:06.235910-epoch:101-loss:0.4152711825124149-acc:0.8293491231984105\n",
      "2018-01-14 14:30:51.862059-epoch:102-loss:0.4484471185454007-acc:0.8111463086358431\n",
      "2018-01-14 14:31:37.411817-epoch:103-loss:0.451723017569246-acc:0.8094258801690464\n",
      "2018-01-14 14:32:22.610556-epoch:104-loss:0.44785645706900234-acc:0.8091721349749073\n",
      "2018-01-14 14:33:08.347623-epoch:105-loss:0.416695642060247-acc:0.8277135429711178\n",
      "Best accuracy model saved in file: ../models/model_christian_0/best_acc_model.ckpt\n",
      "Best loss model saved in file: ../models/model_christian_0/best_loss_model.ckpt\n",
      "2018-01-14 14:33:54.940060-epoch:106-loss:0.43059893414892003-acc:0.8197542387863685\n",
      "2018-01-14 14:34:40.490441-epoch:107-loss:0.41671276092529297-acc:0.8245822006258472\n",
      "2018-01-14 14:35:26.123172-epoch:108-loss:0.4169314308413144-acc:0.8276385644386555\n",
      "2018-01-14 14:36:11.833724-epoch:109-loss:0.41498613254777317-acc:0.8290360569953918\n",
      "2018-01-14 14:36:57.584545-epoch:110-loss:0.4536315017733081-acc:0.8102493306686138\n",
      "Best loss model saved in file: ../models/model_christian_0/best_loss_model.ckpt\n",
      "2018-01-14 14:37:43.552789-epoch:111-loss:0.42574341646556196-acc:0.8209337674338242\n",
      "2018-01-14 14:38:28.999583-epoch:112-loss:0.42435271986599626-acc:0.8215783197304298\n",
      "2018-01-14 14:39:14.719272-epoch:113-loss:0.42894506454467773-acc:0.818569843111367\n",
      "2018-01-14 14:40:00.401284-epoch:114-loss:0.42642452696274064-acc:0.8206889691023991\n",
      "2018-01-14 14:40:46.136956-epoch:115-loss:0.43575773567988957-acc:0.8176209001705564\n",
      "Best accuracy model saved in file: ../models/model_christian_0/best_acc_model.ckpt\n",
      "Best loss model saved in file: ../models/model_christian_0/best_loss_model.ckpt\n",
      "2018-01-14 14:41:32.359852-epoch:116-loss:0.45467786336767263-acc:0.8125055206233057\n",
      "2018-01-14 14:42:18.035720-epoch:117-loss:0.451299250125885-acc:0.8124431741648707\n",
      "2018-01-14 14:43:03.766560-epoch:118-loss:0.45554711695375105-acc:0.807926307464468\n",
      "2018-01-14 14:43:49.235407-epoch:119-loss:0.4277137887888941-acc:0.8208852307549839\n",
      "2018-01-14 14:44:35.003174-epoch:120-loss:0.4216552253427177-acc:0.8246283675062245\n",
      "2018-01-14 14:45:19.967912-epoch:121-loss:0.4156624027367296-acc:0.828877944370796\n",
      "2018-01-14 14:46:05.401362-epoch:122-loss:0.4275060439931935-acc:0.8234241111525173\n",
      "2018-01-14 14:46:50.788238-epoch:123-loss:0.4459679044526199-acc:0.8112500926543926\n",
      "2018-01-14 14:47:36.077038-epoch:124-loss:0.42137571038870975-acc:0.8256851743007528\n",
      "2018-01-14 14:48:21.667853-epoch:125-loss:0.4490645322306403-acc:0.8143694667980589\n",
      "2018-01-14 14:49:07.162132-epoch:126-loss:0.4655336932889347-acc:0.8044946563654933\n",
      "2018-01-14 14:49:52.808525-epoch:127-loss:0.4263640672996126-acc:0.8216352771068441\n",
      "2018-01-14 14:50:38.489194-epoch:128-loss:0.4391459123841648-acc:0.8183767405049556\n",
      "2018-01-14 14:51:24.114543-epoch:129-loss:0.42867617977076566-acc:0.8206199078724301\n",
      "2018-01-14 14:52:09.688288-epoch:130-loss:0.43823608242232226-acc:0.8178649133649365\n",
      "2018-01-14 14:52:55.173492-epoch:131-loss:0.4156480267130095-acc:0.8269788787282746\n",
      "2018-01-14 14:53:40.890919-epoch:132-loss:0.45006955286552164-acc:0.8078285702343644\n",
      "2018-01-14 14:54:26.237106-epoch:133-loss:0.4482777951092556-acc:0.8112589120864868\n",
      "2018-01-14 14:55:11.938805-epoch:134-loss:0.425501077339567-acc:0.8237477047690029\n",
      "2018-01-14 14:55:57.350643-epoch:135-loss:0.40891951733622056-acc:0.8300644426510252\n",
      "2018-01-14 14:56:43.017480-epoch:136-loss:0.4232405146648144-acc:0.8236961323639442\n",
      "2018-01-14 14:57:28.626084-epoch:137-loss:0.4259524109034703-acc:0.822061733952884\n",
      "2018-01-14 14:58:14.023846-epoch:138-loss:0.4577067288859137-acc:0.8082222774110991\n",
      "2018-01-14 14:58:59.576405-epoch:139-loss:0.4279092334467789-acc:0.8207329080022614\n",
      "2018-01-14 14:59:45.327293-epoch:140-loss:0.41557464311862813-acc:0.828501600643684\n",
      "2018-01-14 15:00:30.597029-epoch:141-loss:0.44077148005880157-acc:0.8151333290955116\n",
      "2018-01-14 15:01:15.952443-epoch:142-loss:0.4183075839075549-acc:0.8263323512570612\n",
      "2018-01-14 15:02:01.644183-epoch:143-loss:0.4186382941130934-acc:0.8263695794960548\n",
      "2018-01-14 15:02:47.256482-epoch:144-loss:0.40976695253931245-acc:0.8293730596016193\n",
      "2018-01-14 15:03:32.681730-epoch:145-loss:0.4141624652106186-acc:0.8267882733509458\n",
      "Best accuracy model saved in file: ../models/model_christian_0/best_acc_model.ckpt\n",
      "Best loss model saved in file: ../models/model_christian_0/best_loss_model.ckpt\n",
      "2018-01-14 15:04:19.198889-epoch:146-loss:0.415033011600889-acc:0.8285172540566017\n",
      "2018-01-14 15:05:04.898162-epoch:147-loss:0.42313019777166433-acc:0.8253188256559701\n",
      "2018-01-14 15:05:50.339258-epoch:148-loss:0.41079873771503056-acc:0.8313347368404782\n",
      "2018-01-14 15:06:35.676141-epoch:149-loss:0.41655320854022587-acc:0.8266006995891703\n",
      "2018-01-14 15:07:21.326485-epoch:150-loss:0.4305191122252366-acc:0.8228809730759983\n",
      "Best accuracy model saved in file: ../models/model_christian_0/best_acc_model.ckpt\n",
      "Best loss model saved in file: ../models/model_christian_0/best_loss_model.ckpt\n",
      "Model saved in file: ../models/model_christian_0/model.ckpt\n",
      "2018-01-14 15:08:07.870227-epoch:151-loss:0.410665838882841-acc:0.8299805234218466\n",
      "2018-01-14 15:08:53.488972-epoch:152-loss:0.41732133668044524-acc:0.8267194834248773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-14 15:09:38.633312-epoch:153-loss:0.4241729347870268-acc:0.8249397257278706\n",
      "2018-01-14 15:10:24.447892-epoch:154-loss:0.41903244010333357-acc:0.8266645012230709\n",
      "2018-01-14 15:11:09.996006-epoch:155-loss:0.421502287017888-acc:0.8267943242500568\n",
      "Best accuracy model saved in file: ../models/model_christian_0/best_acc_model.ckpt\n",
      "Best loss model saved in file: ../models/model_christian_0/best_loss_model.ckpt\n",
      "2018-01-14 15:11:56.318947-epoch:156-loss:0.45221821295803993-acc:0.8085604741655548\n",
      "2018-01-14 15:12:41.396150-epoch:157-loss:0.43508486192801904-acc:0.819073249553812\n",
      "2018-01-14 15:13:26.989298-epoch:158-loss:0.4345459177576262-acc:0.8168167924058848\n",
      "2018-01-14 15:14:12.690289-epoch:159-loss:0.4263067553783285-acc:0.824450394202923\n",
      "2018-01-14 15:14:58.204593-epoch:160-loss:0.4258369998685245-acc:0.8216334355288538\n",
      "2018-01-14 15:15:44.128554-epoch:161-loss:0.4341485510612356-acc:0.8190783755532627\n",
      "2018-01-14 15:16:29.632455-epoch:162-loss:0.420163482427597-acc:0.8273041823814655\n",
      "2018-01-14 15:17:15.345160-epoch:163-loss:0.42690811280546515-acc:0.8247571505349258\n",
      "2018-01-14 15:18:01.077005-epoch:164-loss:0.43219953672639255-acc:0.8224788513676874\n",
      "2018-01-14 15:18:46.860365-epoch:165-loss:0.44958391785621643-acc:0.8122778267695986\n",
      "2018-01-14 15:19:32.699506-epoch:166-loss:0.4197420066800611-acc:0.8273525854636883\n",
      "2018-01-14 15:20:18.831261-epoch:167-loss:0.4417089830184805-acc:0.8157534147131033\n",
      "2018-01-14 15:21:04.488157-epoch:168-loss:0.4168249317284288-acc:0.8264181243962255\n",
      "2018-01-14 15:21:50.187782-epoch:169-loss:0.4229883962664111-acc:0.8250277247922173\n",
      "2018-01-14 15:22:36.107843-epoch:170-loss:0.4365549817167479-acc:0.819909848015884\n",
      "2018-01-14 15:23:21.632132-epoch:171-loss:0.41831437267106153-acc:0.8261610865592957\n",
      "2018-01-14 15:24:07.127520-epoch:172-loss:0.4132553308174528-acc:0.8292783519317364\n",
      "2018-01-14 15:24:52.639400-epoch:173-loss:0.44543863884333906-acc:0.8206326673770774\n",
      "2018-01-14 15:25:38.276163-epoch:174-loss:0.4161633766930679-acc:0.8279599136319653\n",
      "2018-01-14 15:26:23.918514-epoch:175-loss:0.4120359163859795-acc:0.8283221824415798\n",
      "2018-01-14 15:27:09.812906-epoch:176-loss:0.43156832662122-acc:0.8234264768403152\n",
      "2018-01-14 15:27:55.382536-epoch:177-loss:0.4221597529690841-acc:0.8263907638089409\n",
      "2018-01-14 15:28:41.254030-epoch:178-loss:0.4347653645893623-acc:0.8190358938841984\n",
      "2018-01-14 15:29:27.064462-epoch:179-loss:0.4212119435441905-acc:0.825062714774033\n",
      "2018-01-14 15:30:12.676519-epoch:180-loss:0.4213396865746071-acc:0.8231612896097118\n",
      "2018-01-14 15:30:58.497352-epoch:181-loss:0.43950094642310306-acc:0.823763619209158\n",
      "2018-01-14 15:31:44.093598-epoch:182-loss:0.4405707264768666-acc:0.8210051922962583\n",
      "2018-01-14 15:32:29.872185-epoch:183-loss:0.42930438703504104-acc:0.8251345363156549\n",
      "2018-01-14 15:33:15.238807-epoch:184-loss:0.4356301498824152-acc:0.8237327049518454\n",
      "2018-01-14 15:34:00.793529-epoch:185-loss:0.4288688918639874-acc:0.8232619186927532\n",
      "2018-01-14 15:34:46.595640-epoch:186-loss:0.4310813936693915-acc:0.8191463885636165\n",
      "2018-01-14 15:35:32.437159-epoch:187-loss:0.4369179966120884-acc:0.8184622443955519\n",
      "2018-01-14 15:36:18.014469-epoch:188-loss:0.44606514634757205-acc:0.8215439895103718\n",
      "2018-01-14 15:37:03.764478-epoch:189-loss:0.43728005577777995-acc:0.8231464233891718\n",
      "2018-01-14 15:37:49.636009-epoch:190-loss:0.45060531949174815-acc:0.8135661380044346\n",
      "2018-01-14 15:38:35.502479-epoch:191-loss:0.43961173193208103-acc:0.8206652957817604\n",
      "2018-01-14 15:39:21.070712-epoch:192-loss:0.4342635818596544-acc:0.8231428758851413\n",
      "2018-01-14 15:40:06.156502-epoch:193-loss:0.446071260961993-acc:0.8194501112247335\n",
      "2018-01-14 15:40:51.781869-epoch:194-loss:0.4222628083722345-acc:0.8267081708743654\n",
      "2018-01-14 15:41:37.061794-epoch:195-loss:0.4310599216099443-acc:0.8196724159964199\n",
      "2018-01-14 15:42:22.513020-epoch:196-loss:0.48306005782094497-acc:0.7965587788614733\n",
      "2018-01-14 15:43:08.203100-epoch:197-loss:0.45223439150843125-acc:0.820104011173906\n",
      "2018-01-14 15:43:54.012255-epoch:198-loss:0.47500852058673726-acc:0.8160939689340263\n",
      "2018-01-14 15:44:39.628912-epoch:199-loss:0.41934023848895374-acc:0.8302637338638306\n",
      "2018-01-14 15:45:24.615981-epoch:200-loss:0.425104387875261-acc:0.8262081824499985\n",
      "Model saved in file: ../models/model_christian_0/model.ckpt\n",
      "2018-01-14 15:46:10.977380-epoch:201-loss:0.43211443054264986-acc:0.8230865721044869\n",
      "2018-01-14 15:46:56.820859-epoch:202-loss:0.4244342826563736-acc:0.8250740314352102\n",
      "2018-01-14 15:47:42.618425-epoch:203-loss:0.4376172587789338-acc:0.8178647756576538\n",
      "2018-01-14 15:48:28.415362-epoch:204-loss:0.4194186874504747-acc:0.8281368366603195\n",
      "2018-01-14 15:49:14.457043-epoch:205-loss:0.43087946854788683-acc:0.8264394340843989\n",
      "2018-01-14 15:50:00.257990-epoch:206-loss:0.4284618332468231-acc:0.8246598099840099\n",
      "2018-01-14 15:50:46.191423-epoch:207-loss:0.4581186925542765-acc:0.8086930595595261\n",
      "2018-01-14 15:51:32.175934-epoch:208-loss:0.4363322987638671-acc:0.8242380865688982\n",
      "2018-01-14 15:52:18.015156-epoch:209-loss:0.4830686963837723-acc:0.8095726761324653\n",
      "2018-01-14 15:53:03.478579-epoch:210-loss:0.4697522284655736-acc:0.8062950701549134\n",
      "2018-01-14 15:53:49.280804-epoch:211-loss:0.44039009151787595-acc:0.8193593477380686\n",
      "2018-01-14 15:54:35.130154-epoch:212-loss:0.4277744683726081-acc:0.8274754470792312\n",
      "2018-01-14 15:55:21.198478-epoch:213-loss:0.44968399713779317-acc:0.8169066371588872\n",
      "2018-01-14 15:56:06.678489-epoch:214-loss:0.4247516249788218-acc:0.8253847319504312\n",
      "2018-01-14 15:56:52.241832-epoch:215-loss:0.48548702535958127-acc:0.7935468780583349\n",
      "2018-01-14 15:57:37.992672-epoch:216-loss:0.4417652117794958-acc:0.8211063557657702\n",
      "2018-01-14 15:58:23.698702-epoch:217-loss:0.480711018217021-acc:0.8144611469630538\n",
      "2018-01-14 15:59:09.497805-epoch:218-loss:0.4382684045824511-acc:0.8250898184447453\n",
      "2018-01-14 15:59:54.943781-epoch:219-loss:0.432817568039072-acc:0.8220213507783825\n",
      "2018-01-14 16:00:39.457884-epoch:220-loss:0.43204512472810414-acc:0.8222214291835652\n",
      "2018-01-14 16:01:25.232647-epoch:221-loss:0.4970078447769428-acc:0.7910049701559133\n",
      "2018-01-14 16:02:11.086820-epoch:222-loss:0.4566947653375823-acc:0.806423189311192\n",
      "2018-01-14 16:02:56.858782-epoch:223-loss:0.42217020227991303-acc:0.8270286033893454\n",
      "2018-01-14 16:03:42.259518-epoch:224-loss:0.42957110035008395-acc:0.8243229327530697\n",
      "2018-01-14 16:04:27.711138-epoch:225-loss:0.45478478587906934-acc:0.8104609744302158\n",
      "2018-01-14 16:05:13.366705-epoch:226-loss:0.45707444589713525-acc:0.8143346083575282\n",
      "2018-01-14 16:05:59.002318-epoch:227-loss:0.42924267772970526-acc:0.8256767577138441\n",
      "2018-01-14 16:06:44.692316-epoch:228-loss:0.4247863138544148-acc:0.8301420561198531\n",
      "2018-01-14 16:07:30.541514-epoch:229-loss:0.4198008015238005-acc:0.8295780070896805\n",
      "2018-01-14 16:08:16.020128-epoch:230-loss:0.433036719930583-acc:0.8235152692630373\n",
      "2018-01-14 16:09:00.940757-epoch:231-loss:0.4532229499570255-acc:0.8154596768576523\n",
      "2018-01-14 16:09:46.424764-epoch:232-loss:0.4262483099411274-acc:0.8275868666583094\n",
      "2018-01-14 16:10:32.587379-epoch:233-loss:0.4395482940920468-acc:0.8250591693253352\n",
      "2018-01-14 16:11:18.136708-epoch:234-loss:0.43928088093626094-acc:0.8232680990778167\n",
      "2018-01-14 16:12:03.757713-epoch:235-loss:0.43732737775506647-acc:0.8272352547481143\n",
      "2018-01-14 16:12:49.095835-epoch:236-loss:0.4568292447205248-acc:0.811639588454674\n",
      "2018-01-14 16:13:33.966519-epoch:237-loss:0.4652738016227196-acc:0.8151954104160439\n",
      "2018-01-14 16:14:19.335935-epoch:238-loss:0.4575388082142534-acc:0.822459915588642\n",
      "2018-01-14 16:15:05.040279-epoch:239-loss:0.4177077145412051-acc:0.8316318886033419\n",
      "2018-01-14 16:15:50.901011-epoch:240-loss:0.42611353047962847-acc:0.8278745433379864\n",
      "2018-01-14 16:16:36.579192-epoch:241-loss:0.44550407446663953-acc:0.8230383026188818\n",
      "2018-01-14 16:17:22.309286-epoch:242-loss:0.4552704373310352-acc:0.8173229653259804\n",
      "2018-01-14 16:18:08.121622-epoch:243-loss:0.4425625862746403-acc:0.8196113870061678\n",
      "2018-01-14 16:18:53.703719-epoch:244-loss:0.42672427769364984-acc:0.8282549669002665\n",
      "2018-01-14 16:19:39.249159-epoch:245-loss:0.4568683258418379-acc:0.8128283229367486\n",
      "2018-01-14 16:20:25.093100-epoch:246-loss:0.4292138270263014-acc:0.824595488350967\n",
      "2018-01-14 16:21:10.557117-epoch:247-loss:0.43861211579421466-acc:0.8213291825919316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-14 16:21:56.319930-epoch:248-loss:0.46388032313050886-acc:0.8049696540010387\n"
     ]
    }
   ],
   "source": [
    "from AxonDeepSeg.train_network import train_model\n",
    "train_model(path_trainingset, path_model, config_network, path_model_init=path_model_init,gpu='/gpu:0')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
