{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train network notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is coded to help train a U-net using atrous (dilated) convolutions.\n",
    "It can be used either in GUI mode with jupyter or in console mode (TO CHECK)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the modules.\n",
    "We also import a set of configuration functions that help us when manipulation config files, which are the backbone of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "from AxonDeepSeg.config_tools import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the name of the directory we are going to save our model to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_model_save='no_dilation_without_bn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define the configuration of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'balanced_weights': [1.1, 1, 1.3],\n",
       " 'batch_norm_activate': True,\n",
       " 'batch_norm_decay_decay_activate': True,\n",
       " 'batch_norm_decay_decay_period': 24000,\n",
       " 'batch_norm_decay_ending_decay': 0.9,\n",
       " 'batch_norm_decay_starting_decay': 0.7,\n",
       " 'batch_size': 8,\n",
       " 'convolution_per_layer': [3, 3, 3, 3],\n",
       " 'da-elastic-activate': True,\n",
       " 'da-elastic-alpha_max': 9,\n",
       " 'da-elastic-order': 3,\n",
       " 'da-flipping-activate': True,\n",
       " 'da-flipping-order': 4,\n",
       " 'da-gaussian_blur-activate': True,\n",
       " 'da-gaussian_blur-order': 6,\n",
       " 'da-gaussian_blur-sigma_max': 1.5,\n",
       " 'da-noise_addition-activate': False,\n",
       " 'da-noise_addition-order': 5,\n",
       " 'da-random_rotation-activate': False,\n",
       " 'da-random_rotation-high_bound': 89,\n",
       " 'da-random_rotation-low_bound': 5,\n",
       " 'da-random_rotation-order': 2,\n",
       " 'da-rescaling-activate': False,\n",
       " 'da-rescaling-factor_max': 1.2,\n",
       " 'da-rescaling-order': 1,\n",
       " 'da-shifting-activate': True,\n",
       " 'da-shifting-order': 0,\n",
       " 'da-shifting-percentage_max': 0.1,\n",
       " 'da-type': 'all',\n",
       " 'dataset_mean': 120.95,\n",
       " 'dataset_variance': 60.23,\n",
       " 'depth': 4,\n",
       " 'dilation_rate': [[1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1]],\n",
       " 'downsampling': 'convolution',\n",
       " 'dropout': 0.75,\n",
       " 'features_per_convolution': [[[1, 16], [16, 16], [16, 16]],\n",
       "  [[16, 32], [32, 32], [32, 32]],\n",
       "  [[32, 64], [64, 64], [64, 64]],\n",
       "  [[64, 128], [128, 128], [128, 128]]],\n",
       " 'learning_rate': 0.001,\n",
       " 'learning_rate_decay_activate': True,\n",
       " 'learning_rate_decay_period': 16000,\n",
       " 'learning_rate_decay_rate': 0.99,\n",
       " 'learning_rate_decay_type': 'polynomial',\n",
       " 'n_classes': 3,\n",
       " 'size_of_convolutions_per_layer': [[5, 5, 5],\n",
       "  [3, 3, 3],\n",
       "  [3, 3, 3],\n",
       "  [3, 3, 3]],\n",
       " 'thresholds': [0, 0.2, 0.8],\n",
       " 'trainingset': 'SEM_3c_512',\n",
       " 'trainingset_patchsize': 512,\n",
       " 'weighted_cost-balanced_activate': True,\n",
       " 'weighted_cost-balanced_weights': [1.1, 1, 1.3],\n",
       " 'weighted_cost-boundaries_activate': False,\n",
       " 'weighted_cost-boundaries_sigma': 2,\n",
       " 'weighted_cost_activate': True}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_configuration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionnary with the updates\n",
    "update_dict={\n",
    "    'dilation_rate': [[1, 1, 1], [1, 1, 1], [1,1,1,1,1,1]],\n",
    "    'convolution_per_layer': [3, 3, 6],\n",
    "    'features_per_convolution': [[[1, 16], [16, 16], [16, 16]],\n",
    "  [[16, 32], [32, 32], [32, 32]],\n",
    "  [[32, 64], [64, 64], [64, 64],[64, 128], [128, 128], [128, 128]]],\n",
    "    'size_of_convolutions_per_layer': [[5, 5, 5],\n",
    "  [3, 3, 3],\n",
    "  [3, 3, 3, 3, 3, 3]]\n",
    "}\n",
    "\n",
    "\n",
    "config=update_config(default_configuration(),update_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnary with the updates\n",
    "update_dict={\n",
    "    'batch_norm_activate':False\n",
    "}\n",
    "\n",
    "\n",
    "config=update_config(default_configuration(),update_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'balanced_weights': [1.1, 1, 1.3],\n",
       " 'batch_norm_activate': True,\n",
       " 'batch_norm_decay_decay_activate': True,\n",
       " 'batch_norm_decay_decay_period': 24000,\n",
       " 'batch_norm_decay_ending_decay': 0.9,\n",
       " 'batch_norm_decay_starting_decay': 0.7,\n",
       " 'batch_size': 8,\n",
       " 'convolution_per_layer': [3, 3, 6],\n",
       " 'da-elastic-activate': True,\n",
       " 'da-elastic-alpha_max': 9,\n",
       " 'da-elastic-order': 3,\n",
       " 'da-flipping-activate': True,\n",
       " 'da-flipping-order': 4,\n",
       " 'da-gaussian_blur-activate': True,\n",
       " 'da-gaussian_blur-order': 6,\n",
       " 'da-gaussian_blur-sigma_max': 1.5,\n",
       " 'da-noise_addition-activate': False,\n",
       " 'da-noise_addition-order': 5,\n",
       " 'da-random_rotation-activate': False,\n",
       " 'da-random_rotation-high_bound': 89,\n",
       " 'da-random_rotation-low_bound': 5,\n",
       " 'da-random_rotation-order': 2,\n",
       " 'da-rescaling-activate': False,\n",
       " 'da-rescaling-factor_max': 1.2,\n",
       " 'da-rescaling-order': 1,\n",
       " 'da-shifting-activate': True,\n",
       " 'da-shifting-order': 0,\n",
       " 'da-shifting-percentage_max': 0.1,\n",
       " 'da-type': 'all',\n",
       " 'dataset_mean': 120.95,\n",
       " 'dataset_variance': 60.23,\n",
       " 'depth': 4,\n",
       " 'dilation_rate': [[1, 1, 1], [1, 1, 1], [1, 1, 1, 1, 1, 1]],\n",
       " 'downsampling': 'convolution',\n",
       " 'dropout': 0.75,\n",
       " 'features_per_convolution': [[[1, 16], [16, 16], [16, 16]],\n",
       "  [[16, 32], [32, 32], [32, 32]],\n",
       "  [[32, 64], [64, 64], [64, 64], [64, 128], [128, 128], [128, 128]]],\n",
       " 'learning_rate': 0.001,\n",
       " 'learning_rate_decay_activate': True,\n",
       " 'learning_rate_decay_period': 16000,\n",
       " 'learning_rate_decay_rate': 0.99,\n",
       " 'learning_rate_decay_type': 'polynomial',\n",
       " 'n_classes': 3,\n",
       " 'size_of_convolutions_per_layer': [[5, 5, 5], [3, 3, 3], [3, 3, 3, 3, 3, 3]],\n",
       " 'thresholds': [0, 0.2, 0.8],\n",
       " 'trainingset': 'SEM_3c_512',\n",
       " 'trainingset_patchsize': 512,\n",
       " 'weighted_cost-balanced_activate': True,\n",
       " 'weighted_cost-balanced_weights': [1.1, 1, 1.3],\n",
       " 'weighted_cost-boundaries_activate': False,\n",
       " 'weighted_cost-boundaries_sigma': 2,\n",
       " 'weighted_cost_activate': True}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create variables to be used by the network when training as well as the directory to store the model. If the directory already exists we add a timestamp at the end of the directory name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model = os.path.join('../models/', dir_model_save)\n",
    "if os.path.exists(path_model): #If the path exists already we add a timestamp at the end of dir name.\n",
    "    dir_model_save += '_' + str(int(time.time()))[-4:]\n",
    "    path_model = os.path.join('../models/', dir_model_save)\n",
    "os.makedirs(path_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then make sure that the config file is valid by using a function we imported. __update_config__ updates the first config (default_configuration()) with the second (config_network) so that the parameters in config_network are at least the parameters needed by the network to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that the config file has all the necessary parameters\n",
    "\n",
    "config_network = update_config(default_configuration(), config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Management of the config file: if it already exists, we load it, else, we write it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen parameters :\n",
      "\n",
      "trainingset_patchsize  -  512\n",
      "thresholds  -  [0, 0.2, 0.8]\n",
      "learning_rate_decay_type  -  polynomial\n",
      "convolution_per_layer  -  [3, 3, 6]\n",
      "da-gaussian_blur-sigma_max  -  1.5\n",
      "da-shifting-percentage_max  -  0.1\n",
      "da-shifting-activate  -  True\n",
      "batch_norm_decay_decay_activate  -  True\n",
      "da-flipping-activate  -  True\n",
      "batch_norm_decay_starting_decay  -  0.7\n",
      "n_classes  -  3\n",
      "learning_rate_decay_activate  -  True\n",
      "trainingset  -  SEM_3c_512\n",
      "da-random_rotation-activate  -  False\n",
      "da-rescaling-activate  -  False\n",
      "batch_norm_decay_decay_period  -  24000\n",
      "da-shifting-order  -  0\n",
      "features_per_convolution  -  [[[1, 16], [16, 16], [16, 16]], [[16, 32], [32, 32], [32, 32]], [[32, 64], [64, 64], [64, 64], [64, 128], [128, 128], [128, 128]]]\n",
      "batch_norm_decay_ending_decay  -  0.9\n",
      "da-gaussian_blur-order  -  6\n",
      "size_of_convolutions_per_layer  -  [[5, 5, 5], [3, 3, 3], [3, 3, 3, 3, 3, 3]]\n",
      "da-gaussian_blur-activate  -  True\n",
      "dataset_mean  -  120.95\n",
      "dilation_rate  -  [[1, 1, 1], [1, 1, 1], [1, 1, 1, 1, 1, 1]]\n",
      "da-rescaling-factor_max  -  1.2\n",
      "dropout  -  0.75\n",
      "da-type  -  all\n",
      "weighted_cost_activate  -  True\n",
      "da-random_rotation-high_bound  -  89\n",
      "dataset_variance  -  60.23\n",
      "weighted_cost-balanced_weights  -  [1.1, 1, 1.3]\n",
      "da-rescaling-order  -  1\n",
      "da-elastic-alpha_max  -  9\n",
      "weighted_cost-boundaries_activate  -  False\n",
      "da-elastic-activate  -  True\n",
      "da-flipping-order  -  4\n",
      "da-random_rotation-low_bound  -  5\n",
      "weighted_cost-balanced_activate  -  True\n",
      "balanced_weights  -  [1.1, 1, 1.3]\n",
      "learning_rate_decay_period  -  16000\n",
      "downsampling  -  convolution\n",
      "learning_rate  -  0.001\n",
      "da-random_rotation-order  -  2\n",
      "batch_size  -  8\n",
      "da-elastic-order  -  3\n",
      "batch_norm_activate  -  True\n",
      "learning_rate_decay_rate  -  0.99\n",
      "da-noise_addition-activate  -  False\n",
      "weighted_cost-boundaries_sigma  -  2\n",
      "depth  -  4\n",
      "da-noise_addition-order  -  5\n"
     ]
    }
   ],
   "source": [
    "path_config_file=os.path.join(path_model,'config_network.json')\n",
    "if os.path.exists(path_config_file): # if there is already a configfile\n",
    "    with open(path_config_file, 'r') as fd:\n",
    "        config_network = json.loads(fd.read())\n",
    "else: # There is no config file for the moment\n",
    "    with open(path_config_file, 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "        config_network=config\n",
    "   \n",
    "print 'Chosen parameters :\\n'\n",
    "for param_name, param_value in config_network.iteritems():\n",
    "    print param_name, ' - ', param_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We indicate to the network where to find our trainingset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_trainingset = os.path.join('../data/', config_network[\"trainingset\"], 'training/')\n",
    "path_model_init=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last part, but not the least: actually training the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Layer: ', 0, ' Conv: ', 0, 'Features: ', [1, 16])\n",
      "('Size:', 5)\n",
      "('Layer: ', 0, ' Conv: ', 1, 'Features: ', [16, 16])\n",
      "('Size:', 5)\n",
      "('Layer: ', 0, ' Conv: ', 2, 'Features: ', [16, 16])\n",
      "('Size:', 5)\n",
      "('Layer: ', 1, ' Conv: ', 0, 'Features: ', [16, 32])\n",
      "('Size:', 3)\n",
      "('Layer: ', 1, ' Conv: ', 1, 'Features: ', [32, 32])\n",
      "('Size:', 3)\n",
      "('Layer: ', 1, ' Conv: ', 2, 'Features: ', [32, 32])\n",
      "('Size:', 3)\n",
      "('Layer: ', 2, ' Conv: ', 0, 'Features: ', [32, 64])\n",
      "('Size:', 3)\n",
      "('Layer: ', 2, ' Conv: ', 1, 'Features: ', [64, 64])\n",
      "('Size:', 3)\n",
      "('Layer: ', 2, ' Conv: ', 2, 'Features: ', [64, 64])\n",
      "('Size:', 3)\n",
      "('Layer: ', 2, ' Conv: ', 3, 'Features: ', [64, 128])\n",
      "('Size:', 3)\n",
      "('Layer: ', 2, ' Conv: ', 4, 'Features: ', [128, 128])\n",
      "('Size:', 3)\n",
      "('Layer: ', 2, ' Conv: ', 5, 'Features: ', [128, 128])\n",
      "('Size:', 3)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-71bdb7c94398>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mAxonDeepSeg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_network\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_trainingset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_model_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_model_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/gpu:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data/mawab/axondeepseg-atrous/axondeepseg/AxonDeepSeg/train_network.pyc\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(path_trainingset, path_model, config, path_model_init, save_trainable, gpu, debug_mode, gpu_per)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;31m# Next, we construct the computational graph linking the input and the prediction.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muconv_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbn_updated_decay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapt_bn_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;31m# We also display the total number of variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/mawab/axondeepseg-atrous/axondeepseg/AxonDeepSeg/atrous_network_construction.pyc\u001b[0m in \u001b[0;36muconv_net\u001b[0;34m(x, training_config, phase, bn_updated_decay, verbose)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;31m# For the moment we keem the same number of channels as the last layer we went through\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;31m# the parameters from the last layer are attainable with depth-1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mconv_number\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_of_convolutions_per_layer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m     \u001b[0;31m#    net = conv_relu(net, features_per_convolution[i][conv_number][1],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;31m#                size_of_convolutions_per_layer[i][conv_number], k_stride=1,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from AxonDeepSeg.train_network import train_model\n",
    "train_model(path_trainingset, path_model, config_network, path_model_init=path_model_init,gpu='/gpu:0')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
