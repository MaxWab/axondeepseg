{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train network notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is coded to help train a U-net using atrous (dilated) convolutions.\n",
    "It can be used either in GUI mode with jupyter or in console mode (TO CHECK)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the modules.\n",
    "We also import a set of configuration functions that help us when manipulation config files, which are the backbone of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "from AxonDeepSeg.config_tools import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the name of the directory we are going to save our model to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_model_save='debugging'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define the configuration of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnary with the updates\n",
    "update_dict={'learning_rate_decay_period': 96000,\n",
    "             'batch_norm_decay_decay_period': 48000,\n",
    "             'trainingset': 'SEM_3c_256',\n",
    "             'trainingset_patchsize': 256,\n",
    "             'dropout':0.9,\n",
    "}\n",
    "\n",
    "\n",
    "config=update_config(default_configuration(),update_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create variables to be used by the network when training as well as the directory to store the model. If the directory already exists we add a timestamp at the end of the directory name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model = os.path.join('../models/', dir_model_save)\n",
    "if os.path.exists(path_model): #If the path exists already we add a timestamp at the end of dir name.\n",
    "    dir_model_save += '_' + str(int(time.time()))[-4:]\n",
    "    path_model = os.path.join('../models/', dir_model_save)\n",
    "os.makedirs(path_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then make sure that the config file is valid by using a function we imported. __update_config__ updates the first config (default_configuration()) with the second (config_network) so that the parameters in config_network are at least the parameters needed by the network to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that the config file has all the necessary parameters\n",
    "\n",
    "config_network = update_config(default_configuration(), config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Management of the config file: if it already exists, we load it, else, we write it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen parameters :\n",
      "\n",
      "trainingset_patchsize  -  256\n",
      "thresholds  -  [0, 0.2, 0.8]\n",
      "learning_rate_decay_type  -  polynomial\n",
      "convolution_per_layer  -  [3, 3, 3, 3]\n",
      "da-gaussian_blur-sigma_max  -  1.5\n",
      "da-shifting-percentage_max  -  0.1\n",
      "da-shifting-activate  -  True\n",
      "batch_norm_decay_decay_activate  -  True\n",
      "da-flipping-activate  -  True\n",
      "batch_norm_decay_starting_decay  -  0.7\n",
      "n_classes  -  3\n",
      "learning_rate_decay_activate  -  True\n",
      "trainingset  -  SEM_3c_256\n",
      "da-random_rotation-activate  -  False\n",
      "da-rescaling-activate  -  False\n",
      "batch_norm_decay_decay_period  -  48000\n",
      "da-shifting-order  -  0\n",
      "features_per_convolution  -  [[[1, 16], [16, 16], [16, 16]], [[16, 32], [32, 32], [32, 32]], [[32, 64], [64, 64], [64, 64]], [[64, 128], [128, 128], [128, 128]]]\n",
      "batch_norm_decay_ending_decay  -  0.9\n",
      "da-gaussian_blur-order  -  6\n",
      "size_of_convolutions_per_layer  -  [[5, 5, 5], [3, 3, 3], [3, 3, 3], [3, 3, 3]]\n",
      "da-gaussian_blur-activate  -  True\n",
      "dataset_mean  -  120.95\n",
      "dilation_rate  -  [[1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1]]\n",
      "da-rescaling-factor_max  -  1.2\n",
      "dropout  -  0.9\n",
      "da-type  -  all\n",
      "weighted_cost_activate  -  True\n",
      "da-random_rotation-high_bound  -  89\n",
      "dataset_variance  -  60.23\n",
      "weighted_cost-balanced_weights  -  [1.1, 1, 1.3]\n",
      "da-rescaling-order  -  1\n",
      "da-elastic-alpha_max  -  9\n",
      "weighted_cost-boundaries_activate  -  False\n",
      "da-elastic-activate  -  True\n",
      "da-flipping-order  -  4\n",
      "da-random_rotation-low_bound  -  5\n",
      "weighted_cost-balanced_activate  -  True\n",
      "balanced_weights  -  [1.1, 1, 1.3]\n",
      "learning_rate_decay_period  -  96000\n",
      "downsampling  -  convolution\n",
      "learning_rate  -  0.001\n",
      "da-random_rotation-order  -  2\n",
      "batch_size  -  8\n",
      "da-elastic-order  -  3\n",
      "batch_norm_activate  -  True\n",
      "learning_rate_decay_rate  -  0.99\n",
      "da-noise_addition-activate  -  False\n",
      "weighted_cost-boundaries_sigma  -  2\n",
      "depth  -  4\n",
      "da-noise_addition-order  -  5\n"
     ]
    }
   ],
   "source": [
    "path_config_file=os.path.join(path_model,'config_network.json')\n",
    "if os.path.exists(path_config_file): # if there is already a configfile\n",
    "    with open(path_config_file, 'r') as fd:\n",
    "        config_network = json.loads(fd.read())\n",
    "else: # There is no config file for the moment\n",
    "    with open(path_config_file, 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "        config_network=config\n",
    "   \n",
    "print 'Chosen parameters :\\n'\n",
    "for param_name, param_value in config_network.iteritems():\n",
    "    print param_name, ' - ', param_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We indicate to the network where to find our trainingset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_trainingset = os.path.join('../data/', config_network[\"trainingset\"], 'training/')\n",
    "path_model_init=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last part, but not the least: actually training the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters to train: 123683\n",
      "training start\n",
      "Weighted cost selected\n",
      "2018-01-18 14:29:08.495412-epoch:1-loss:0.8242146345453525-acc:0.6507601962177032\n",
      "2018-01-18 14:29:42.579123-epoch:2-loss:0.7219982666706821-acc:0.6896313308575832\n",
      "2018-01-18 14:30:16.814028-epoch:3-loss:0.6747311725528963-acc:0.711258074559203\n"
     ]
    }
   ],
   "source": [
    "from AxonDeepSeg.train_network import train_model\n",
    "train_model(path_trainingset, path_model, config_network, path_model_init=path_model_init,gpu='/gpu:0')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
